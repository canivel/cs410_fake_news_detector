{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import wordbatch\n",
    "from wordbatch.models import FTRL\n",
    "from wordbatch.extractors import WordBag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'data/df_stemmed_kaggle.csv'\n",
    "df_full = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Loading the datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Loading the datasets\")\n",
    "df = pd.read_csv('data/df_final_v1.csv')\n",
    "kaggle_test_df = pd.read_csv('data/kaggle/test.csv')\n",
    "\n",
    "train_size = df.shape[0]\n",
    "y = df['label']\n",
    "\n",
    "test_ids = kaggle_test_df['id']\n",
    "test_size = kaggle_test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Define helpers for text normalization\n",
    "stopwords = {x: 1 for x in stopwords.words('english')}\n",
    "non_alphanums = re.compile(u'[^A-Za-z0-9]+')\n",
    "\n",
    "def rmsle(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y) - np.log1p(y0), 2)))\n",
    "\n",
    "def normalize_text(text):\n",
    "    return u\" \".join(\n",
    "        [x for x in [y for y in non_alphanums.sub(' ', text).lower().strip().split(\" \")] \\\n",
    "         if len(x) > 1 and x not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb= wordbatch.WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\":2, \"hash_ngrams_weights\":[0.5, -1.0], \n",
    "                                             \"hash_size\":2**23, \"norm\":'l2', \"tf\":'log', \"idf\":50.0})\n",
    "                       , procs=8\n",
    "                       , method=\"serial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n",
      "Extract wordbags\n",
      "Normalize text\n",
      "Extract wordbags\n"
     ]
    }
   ],
   "source": [
    "X_title = wb.transform(df_full['stemmed_title'])\n",
    "X_text = wb.transform(df_full['stemmed_text'])\n",
    "X_author = df_full['author_cat'].values\n",
    "X_author = X_author.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59594, 8388608)\n",
      "(59594, 8388608)\n",
      "(59594, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_title.shape)\n",
    "print(X_text.shape)\n",
    "print(X_author.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59594, 16777217)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_merge = hstack((X_title, X_text, X_author)).tocsr()\n",
    "sparse_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse_merge[:train_size]\n",
    "X_test = sparse_merge[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.05, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_X[:1].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= FTRL(alpha=1, beta=1.0, L1=0.00001, L2=0.8, D=2 ** 25, iters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17462991253007093\n"
     ]
    }
   ],
   "source": [
    "preds= clf.predict(valid_X)\n",
    "print(rmsle(valid_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19307    1\n",
       "5179     0\n",
       "37483    0\n",
       "21443    1\n",
       "15890    0\n",
       "43097    0\n",
       "20292    1\n",
       "41112    0\n",
       "35772    0\n",
       "9417     1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTRL dev f1_score: 0.8963414634146342\n",
      "FTRL dev accuracy_score: 0.925\n",
      "FTRL dev recall_score: 0.8918099089989889\n",
      "FTRL dev precision_score: 0.9009193054136875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score , recall_score , precision_score\n",
    "print(\"FTRL dev f1_score:\", f1_score(valid_y, np.round(preds)))\n",
    "print(\"FTRL dev accuracy_score:\", accuracy_score(valid_y, np.round(preds)))\n",
    "print(\"FTRL dev recall_score:\", recall_score(valid_y, np.round(preds)))\n",
    "print(\"FTRL dev precision_score:\", precision_score(valid_y, np.round(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import gzip\n",
    "print(\"Saving models\")\n",
    "with gzip.open('./data/models/models_ftrl.pkl', 'wb') as model_file:\n",
    "    pkl.dump((wb, clf), model_file, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_cat</th>\n",
       "      <th>stemmed_title</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2191</td>\n",
       "      <td>hous dem aide: we didn't even see comey letter...</td>\n",
       "      <td>hous dem aide: we didn't even see comey letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2114</td>\n",
       "      <td>flynn: hillari clinton, big woman on campus - ...</td>\n",
       "      <td>ever get the feel your life circl the roundabo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1863</td>\n",
       "      <td>whi the truth might get you fire</td>\n",
       "      <td>whi the truth might get you fire octob 29, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4372</td>\n",
       "      <td>15 civilian kill in singl us airstrik have bee...</td>\n",
       "      <td>video 15 civilian kill in singl us airstrik ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3564</td>\n",
       "      <td>iranian woman jail for fiction unpublish stori...</td>\n",
       "      <td>print \\r\\r\\nan iranian woman has been sentenc ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_cat                                      stemmed_title  \\\n",
       "0        2191  hous dem aide: we didn't even see comey letter...   \n",
       "1        2114  flynn: hillari clinton, big woman on campus - ...   \n",
       "2        1863                   whi the truth might get you fire   \n",
       "3        4372  15 civilian kill in singl us airstrik have bee...   \n",
       "4        3564  iranian woman jail for fiction unpublish stori...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  hous dem aide: we didn't even see comey letter...  \n",
       "1  ever get the feel your life circl the roundabo...  \n",
       "2  whi the truth might get you fire octob 29, 201...  \n",
       "3  video 15 civilian kill in singl us airstrik ha...  \n",
       "4  print \\r\\r\\nan iranian woman has been sentenc ...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'title': df_full['stemmed_title'][1],\n",
    "     'text': df_full['stemmed_text'][1],\n",
    "     'author': df_full['author_cat'][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n",
      "Extract wordbags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 8388608)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_wb = wb.transform([d['title']+' '+d['text']])\n",
    "X_test_wb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n",
      "Extract wordbags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 8388608)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text = wb.transform([d['text']])\n",
    "X_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_author = np.array([2114])\n",
    "X_author = X_author.reshape(-1, 1)\n",
    "X_author.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16777217)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_merge = hstack((X_title, X_text, X_author)).tocsr()\n",
    "sparse_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99996022])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2s= clf.predict(X_test_wb)\n",
    "pred2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n",
      "Extract wordbags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x8388608 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts2= ['factual and not.']\n",
    "vec = wb.transform(test_texts2)\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98289872])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2s= clf.predict(vec)\n",
    "pred2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
